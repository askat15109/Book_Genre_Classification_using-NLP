# -*- coding: utf-8 -*-
"""Book_Genre_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CcvjGs8eY3AHcLcM-o2fZnjczS5GXwia
"""

import pandas as pd
import numpy as np
import re
import nltk
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix

# Download NLTK stopwords
nltk.download('stopwords')
from nltk.corpus import stopwords

# Load dataset
df = pd.read_csv("books.csv")

# Inspect columns to check if 'description' column exists
print("Columns in the dataset:", df.columns)

# If 'description' column exists, proceed, else adjust to the correct column name
if 'description' not in df.columns:
    print("Description column not found. Checking for other columns:")
    print(df.columns)
    # Example fix: If the correct column name is 'book_description', update it:
    if 'book_description' in df.columns:
        df['description'] = df['book_description']  # Renaming column to 'description'
    else:
        print("No suitable description column found!")
        # If you can't find a column with descriptions, you might want to use 'title' or 'authors' as a placeholder.
        df['description'] = df['title']  # Just a placeholder for testing, replace it with real descriptions later
else:
    print("'description' column found.")

# Add basic genre tagging (for simplicity, we simulate a genre tag based on title keywords)
def get_genre(title):
    title = title.lower()
    if 'love' in title or 'romance' in title:
        return 'Romance'
    elif 'murder' in title or 'death' in title or 'crime' in title:
        return 'Mystery'
    elif 'magic' in title or 'dragon' in title or 'fantasy' in title:
        return 'Fantasy'
    elif 'history' in title or 'war' in title:
        return 'History'
    else:
        return 'Fiction'

df['genre'] = df['title'].apply(get_genre)

# Clean description
stop_words = set(stopwords.words('english'))

def clean_text(text):
    text = re.sub(r"[^a-zA-Z']", ' ', text)
    text = text.lower()
    text = text.split()
    text = [word for word in text if word not in stop_words]
    return ' '.join(text)

df['clean_description'] = df['description'].apply(clean_text)

# Encode genres
le = LabelEncoder()
df['genre_label'] = le.fit_transform(df['genre'])
num_classes = len(le.classes_)
print("Genres:", list(le.classes_))

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(
    df['clean_description'], df['genre_label'], test_size=0.2, random_state=42
)

# Tokenize text
tokenizer = Tokenizer(num_words=10000)
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Pad sequences to ensure uniform input size
max_len = 150
X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)

# One-hot encode labels
y_train_cat = to_categorical(y_train, num_classes=num_classes)
y_test_cat = to_categorical(y_test, num_classes=num_classes)

# Build LSTM Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout

model = Sequential()
model.add(Embedding(input_dim=10000, output_dim=64, input_length=max_len))
model.add(LSTM(64, return_sequences=False))
model.add(Dropout(0.5))
model.add(Dense(32, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

# Train the model
history = model.fit(
    X_train_pad, y_train_cat,
    validation_data=(X_test_pad, y_test_cat),
    epochs=5,
    batch_size=64
)

# Plot the accuracy
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title("Accuracy over epochs")
plt.show()

# Predictions
y_pred = model.predict(X_test_pad)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_cat, axis=1)

# Classification Report
print("Classification Report:")
print(classification_report(y_true, y_pred_classes, target_names=le.classes_))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", xticklabels=le.classes_, yticklabels=le.classes_, cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Optional: Test with Custom Input
def predict_genre(text):
    text = clean_text(text)
    seq = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(seq, maxlen=max_len)
    pred = model.predict(padded)
    return le.classes_[np.argmax(pred)]

# Try it with a custom example
print(predict_genre("A deep dive into the history of World War II, exploring the events that shaped the global landscape"))

